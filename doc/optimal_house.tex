\documentclass[12pt,final,fleqn]{article}

% basic packages
\usepackage[margin=1in] { geometry }
\usepackage{amssymb,amsmath, bm}
\usepackage{verbatim}
\usepackage[latin1]{inputenc}
%\usepackage[OT1]{fontenc}
\usepackage{setspace}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage[hyphens,spaces,obeyspaces]{url}
\usepackage[font={bf}]{caption}
%\usepackage{pgfplots}
%\usepackage[font={bf}]{caption}
\usepackage{setspace}
\usepackage{latexsym}
%\usepackage{euscript}
\usepackage{graphicx}
\usepackage{marvosym}
%\usepackage[varg]{txfonts}  Older version of ``g'' in math.

% bibliography packages
\usepackage{natbib}
\bibpunct{(}{)}{;}{a}{}{,}
\bibliographystyle{apsr}
\renewcommand{\bibname}{References}

% hyperref options
\usepackage{color}
\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\newcommand*{\Appendixautorefname}{Appendix}
\renewcommand*{\sectionautorefname}{Section}
\renewcommand*{\subsectionautorefname}{Section}
\renewcommand*{\subsubsectionautorefname}{Section}
\newcommand{\aref}[1]{\hyperref[#1]{Appendix~\ref{#1}}}
\hypersetup{pdfstartview={XYZ null null 1.00}}

% packages for tables
\usepackage{longtable}
\usepackage{booktabs, threeparttable}
\usepackage{threeparttablex}
%\usepackage{tabularx}
% dcolumn package
\usepackage{dcolumn}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\captionsetup{belowskip=10pt,aboveskip=-5pt}
\usepackage{multirow}
% rotating package
\usepackage[figuresright]{rotating}
\usepackage{pdflscape}
\usepackage{subcaption}

% packages for figures
\usepackage{grffile}
\usepackage{afterpage}
\usepackage{float}
\usepackage[section]{placeins}

% theorem package
\usepackage{theorem}
\theoremstyle{plain}
\theoremheaderfont{\scshape}
\newtheorem{theorem}{Theorem}
\newtheorem{algorithm}{Algorithm}
\newtheorem{assumption}{Assumption}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newcommand{\qed}{\hfill \ensuremath{\Box}}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\argmin}{arg\min}
\DeclareMathOperator{\argmax}{arg\max}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\providecommand{\norm}[1]{\lVert#1\rVert}
\renewcommand\r{\right}
\renewcommand\l{\left}
\newcommand\E{\mathbb{E}}
\newcommand\dist{\buildrel\rm d\over\sim}
\newcommand\iid{\stackrel{\rm i.i.d.}{\sim}}
\newcommand\ind{\stackrel{\rm indep.}{\sim}}
\newcommand\cov{{\rm Cov}}
\newcommand\var{{\rm Var}}
\newcommand\SD{{\rm SD}}
\newcommand\bone{\mathbf{1}}
\newcommand\bzero{\mathbf{0}}

% dotted lines in tables
%\usepackage{arydshln}

\usepackage{pdflscape}

% spacing between sections and subsections
\usepackage[compact]{titlesec}

% times new roman
%\usepackage{times}

% appendix settings
\usepackage[toc,page,header]{appendix}
\renewcommand{\appendixpagename}{\centering Appendices}
\usepackage{chngcntr}
\usepackage{etoolbox}
\usepackage{lipsum}

% supplement settings
\newcommand{\apsec}[1]{\hyperref[#1]{Supplemental Appendix section~\ref{#1}}}
\newcommand{\aptable}[1]{\hyperref[#1]{Supplemental Table~\ref{#1}}}
\usepackage{xr}
\externaldocument{supplement}


% file paths and definitions
\input{../output/ch1txtstats.txt}
\makeatletter
\newcommand*\ExpandableInput[1]{\@@input#1 }
\makeatother

\setlength{\mathindent}{1cm}
\allowdisplaybreaks[4]
\doublespacing
%\special{pdf: pagesize width 8.5truein height 11.0truein}

\titleformat{\subsection}
  {\itshape\Large}{\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\itshape\large}{\thesubsubsection}{1em}{}  
  

\begin{document}
%\author{Devin Incerti}
\title{\textbf{The Optimal Allocation of Campaign Funds in U.S. House Elections}}
\date{\today}
\maketitle

\thispagestyle{empty}
\setcounter{page}{0}

\begin{singlespacing}
\begin{abstract}
How should political parties allocate resources in U.S. House elections? Are actual spending strategies optimal? This paper answers these questions by using Bayesian election forecasts to estimate a probabilistic voting model. The model provides real-time estimates of the marginal value of additional resources in a district during a campaign and can be used to compare actual spending patterns to the amount that should have been spent according to the model. The correlation between observed and optimal spending is over $0.5$ in each non-redistricting year from 2000 to 2010 and observed spending patterns respond to new polls during a campaign. The correlations are consistent across different types of campaign donors including the Democratic Congressional Campaign Committee and the National Republican Congressional Committee, various political action committees, and individuals. There is also evidence that spending is based on maximizing total seats rather than the probability of winning a majority of seats.
\end{abstract}
\end{singlespacing}

\clearpage
\doublespacing

\section{Introduction}
The allocation of campaign resources is a major strategic activity for political parties. During the 2016 election cycle, the Democratic party spent almost \$1.3 billion while the Republican party spent over \$900 million.\footnote{Data accessed from \url{https://www.opensecrets.org/parties/index.php?cmte=&cycle=2016}.} A key aim of this spending is to influence the outcome of elections by encouraging voters of the same party to turnout and to elicit votes from uncertain voters. However, some voters have a much larger probability of influencing an election than others \citep{chamberlain1981note, gelman2004standard, gelman2012probability} To ensure that spending maximizes electoral success, it is therefore critical that resources are allocated efficiently. 

Prior studies have derived optimal allocation decisions given two separate objectives: maximizing legislative seats (or electoral college votes in U.S. presidential elections) and maximizing the probability of winning a majority of seats (or the electoral college). Literature focusing on the first objective dates back to Brams and Davis (\citeyear{brams1973resource, brams19743}), who develop a model in which U.S. presidential candidates aiming to maximize electoral college votes should allocate resources roughly in proportion to the 3/2 power of the number of electoral votes in a given state. They provide some empirical support by showing that the number of campaign visits by political candidates across electoral districts between 1960 and 1972 fits the 3/2's rule very closely. However, this was challenged by \citet{colantoni1975campaign}, who argue that the approach taken by Brams and Davis does not account for electoral competitiveness and that there is less empirical support for the 3/2's rule after doing so. Likewise, \citet{jacobson1985party} argues that every congressional seat is valuable so parties should aim to maximize seats and \citet{snyder1989election} develop a model in which parties maximizing seat share allocate more resource to close races. \citet{pattie1995winning} provide supporting evidence by showing that local party campaigners spent the most on close seats during the 1983, 1987, and 1992 British general elections.  

Scholars have reached different conclusions about whether campaign strategies would change under the second objective. \citet{brams1973resource} posit that the implications of this distinction would be relatively minor and \citet{aranson1974election} generate results supportive of this notion showing that the two goals are equivalent if the expected number of seats won by each party are the same. However, in more realistic settings in which this is not the case, optimal strategies differ. For example, \citet{snyder1989election} and \citet{stromberg2008electoral} derive results showing that optimal strategies depend on both the probability a district election is close and the probability that a district is pivotal (i.e., the winning party would lose if the result in that district changed). \citet{stromberg2008electoral} provide strong evidence that party strategies are consistent with this by demonstrating that the correlation between predicted and actual presidential campaign visits was 0.9 during the 2000 and 2004 US presidential elections.

This paper revisits this literature by using the probabilistic voting model of \citet{stromberg2008electoral} to calculate optimal campaign spending in U.S. House elections when parties maximize legislative seats and when they try to win a majority of seats. It then tests the extent to which actual spending matches the model's predictions. The marginal value of additional spending depends on predicted vote shares as well as uncertainty at the district and national levels. Two forecasting models are used to estimate the parameters: the first is a Bayesian hierarchical model that uses information about districts and candidates to provide a forecast as of September 1st of each election year, and the second is a dynamic linear model (DLM) that uses the hierarchical model as a prior, incorporates all available district and national polls, and is capable of providing real-time forecasts at any date during a campaign. The hierarchical model is used to forecast each non-redistricting year election from 2000 to 2010 and the DLM is used to analyze the 2010 election at various stages of the campaign.

The major innovation is the integration of a probabilistic voting model with Bayesian forecasts to produce (real-time in the case of the DLM) quantitative measures of how legislative parties in two-party systems should allocate resources during a political campaign according to different objectives. The benefits of the model are threefold. First, it can provide guidance on how actual campaigns should allocate resources during a campaign given historical results and available polls. Second, the results can be used to evaluate the extent to which the observed spending strategies of political parties are consistent with optimal strategies when parties are both trying to win a majority of seats and when they are trying maximize total seats. Third, the DLM can be used to track the extent to which optimal spending patterns vary over the course of a campaign as forecasted outcomes change.

I provide evidence showing that (i) parties donate in a manner consistent with maximizing total seats rather than winning a majority of seats, (ii) seat maximization based spending is highly correlated with actual spending, and (iii) spending patterns respond to new polls. For instance, actual spending during the 2008 election---which was lopsided enough to yield spending strategies that were very sensitive to party objectives---is highly correlated ($r \approx \cormaxseats2008$) with a seat maximization based spending strategy but not ($r \approx \cormaj2008$) one based on maximizing the probability of winning a majority of seats.\footnote{$r$ refers to Pearson's correlation coefficient.}. Moreover, correlations between optimal spending based on seat maximization and actual spending are over $0.5$ in each non-redistricting election year from 2000 to 2010 and generally increase over time. The correlations are even higher when incorporating polling data into the forecasts: correlations reach a peak of over 0.8 when comparing spending in the final month of the 2010 campaign with predicted spending based on a forecast made using all information including polls up until that date. Finally, spending allocations changed over the course of the 2010 election and tracked changes in poll-based forecasts.  

I examine campaign contributions from political action committees (PACs) and individuals in addition to national political parties, which helps shed light on current debates about whether contributors donate to buy access to politicians or influence votes \citep[e.g.,][]{stratmann2005some}. Empirical research has provided support for each motive. For instance, one of the robust findings in the literature is that contributors spend more on close elections \citep{jacobson1985money,kau1982general, poole1985patterns, stratmann1991campaign}.\footnote{These studies have two limitations that this paper overcomes. First, the closeness of an election is typically measured with an ex-post measure of the electoral margin or the lagged vote from the previous election. This does not mimic the decision of contributors who must make choices prior to election day and have considerably more information available to them than the vote in the previous election. Second, since they are not driven by theory, they do not provide any guidance the functional form of the relationship between the closeness of an election and spending, which should depend on the uncertainty (and probability distribution) of the predicted vote.} On the other hand, research has shown that campaign contributions can influence congressional voting \citep{facchini2011interest, mian2010Apolitical, richter2009lobbying} and that candidates serving on congressional committees raise more money \citep{grier1991committee,kroszner1998interest, romer1994empirical}. 

Most of the evidence in this paper suggests that contributors aim to influence elections rather than buy access: the explanatory power of a seat maximization based spending strategy is considerably larger than other potential determinants of campaign contributions such as incumbency and party leadership. It is only in cases where actors have the largest incentives to influence votes--like financial service firms buying access to candidates--that they are on close to equal footing.\footnote{Members of the House Committee on Financial Services receive a higher proportion of funding from the financial services industry than any other committee receives from a single industry.}

The remainder of this paper is organized as follows. \autoref{sec:campaign-spending-model} introduces the probabilistic voting model. \autoref{sec:model-estimation} describes the Bayesian forecasting techniques used to estimate the model. \autoref{sec:forecasting-results} evaluates the performance of the forecasts and examines optimal spending strategies according to the model. \autoref{sec:actual-vs-optimal} compares actual campaign spending to predicted spending from the model. \autoref{sec:discussion} discusses limitations of the modeling approach and potential extensions to the model and empirical exercises. Finally, \autoref{sec:conclusion} concludes. 

\section{Campaign Spending Model} \label{sec:campaign-spending-model}
This section introduces a version of Stromberg's \citeyear{stromberg2008electoral} model suitable for analyzing U.S. House elections, with foundations that date back to the probabilistic voting models of \citet{lindbeck1987balanced} and \citet{dixit1996determinants}. 

\subsection{Set up}
The model considers electoral competition between two parties, labeled Republican $R$ and Democrat $D$.\footnote{Third party candidates are ignored.} During the campaign, each party must decide how to optimally allocate funds across the 435 Congressional districts. More formally, party $J = D, R$ must choose expenditures in district $i$, $e^J_i$, subject to the resource constraint, 
\begin{align} \label{eqn: budget constraint}
\sum_{i=1}^{435} e^J_i \leq E^J,
\end{align}
where $E^J$ is the amount of money party $J$ has to spend on candidates.

The share of votes received by party $D$ in district $i$ is assumed to depend on four primary factors: campaign spending, predetermined characteristics of the district, the national political climate, and unknown shocks. A critical assumption is that the impact of campaign spending on the probability a party wins an electoral district, $u(e^J_i)$, is an increasing concave function. The predetermined district characteristics and the national climate are known before the spending decision is made and can be used to make a prediction, $V_i$, of party $D$'s vote share. Finally, there are two sources of uncertainty, a national error, $\delta$, and a district specific error, $\epsilon_i$. The national errors represent uncertain national swings that affect all districts equally and the district errors are unpredictable swings unique to each district. Both error terms are independently drawn from normal distributions: $h(\delta) = N(\delta|0, \sigma^2_\delta)$ and $g_i(\epsilon_i) = N(\epsilon_i|0, \sigma^2)$. 

Letting $u(e^D_i) - u(e^R_i) = \Delta u_i$, party $R$ wins a district if $\Delta u_i + V_i + \delta + \epsilon_i \leq 1/2$. The probability of a victory by party $R$ conditional on expenditures, $e^D_i$ and $e^R_i$, and the national swing, $\delta$, is therefore,
\begin{align}\label{eqn: Republican wins}
G_i(1/2 - \Delta u_i - V_i - \delta),
\end{align}
where $G_i(\cdot)$ is the cumulative density function of $\epsilon_i$. 

\subsection{Party goals}
Optimal strategies depend on the objective of the political parties. Unlike in presidential campaigns where the goal is clearly to win the election, the goals of the parties in House campaigns are less straightforward. As a result, I consider two plausible objective functions. 

The first objective function assumes that parties simply maximize the expected number of House seats. For party $R$, this is given by,
\begin{align} \label{eqn: expected number of seats}
\E\left[S (\Delta \mu)\right] = \int \sum_{i=1}^{435} G_i(1/2 - \Delta u_i - V_i - \delta)h(\delta) d\delta,
\end{align}
where $S$ is the total number of seats won by the Republican party. 

A second possibility is that parties maximize the probability of winning a majority of seats. For party $R$ this is,
\begin{align}
P^R(\Delta \mu) = \int \rm{Pr}\left(S(\Delta \mu) > 218 \right) h(\delta)d \delta.
\end{align}

\subsection{Equilibrium} \label{sec:equilibrium}
Each party derives its optimal strategy given these goals based on their expectation of what the other party will do. Specifically, there is a Nash equilibrium in which each party allocates spending so that,
\begin{align}
\frac{\partial f^J}{\partial e_i^J}= Q_i u'(e^{J*}_i)=\lambda^J,
\end{align}
where $f^R(e^D, e^R)$ is the objective function used by party R (i.e., either to maximize total seats or the probability of winning a majority of seats), $Q_i = \partial f^J/ \partial \Delta u_i$ and $\lambda^J$ is the Lagrange multiplier for party $j$. Since $u'(e^J)$ is decreasing in $e^J$, the parties allocate more resources to districts with higher values of $Q_i$. 

The value of $Q_i$ depends on the choice of the objective function. When parties maximize the expected number of seats, $Q_i$ is calculated as, 
\begin{align} \label{eqn: Q_i expected seats}
Q_i = Q_i^{seats} = \int  g_i(1/2 - \Delta u_i - V_i - \delta) h(\delta) d\delta,
\end{align}
where $g_i(\cdot)$ is the probability density function of $\epsilon_i$. Not unexpectedly, districts with a predicted vote share close to 1/2 should receive the most expenditures. Spending should also be more concentrated when the error terms, $\sigma$ and $\delta$, are smaller. If on the other hand, parties maximize the probability of winning a majority of seats, $Q_i$ is more complicated. For party $R$, it is,
\begin{align} \label{eqn: Q_i probability of winning}
Q_i  = Q_i^{maj}
& = \int \frac{1}{\sigma_S}\phi(x(\delta))g_i(\cdot)h(\delta)d\delta \nonumber \\
 &\qquad + \int \frac{1}{\sigma_S}\phi(x(\delta))x(\delta)\left(1-2G_i(\cdot)\right) g_i(\cdot)h(\delta)d\delta,
\end{align}
where $x(\delta) = \left(218 - \mu_S(\Delta u,\delta)\right)/\sigma_S(\Delta u, \delta)$, $\phi(\cdot)$ is the standard normal probability density function, $\mu_S$ is the mean number of seats won by party $R$, $\sigma_S$ is the variance of the number of seats won by party $R$, and $\Delta \mu = \left(\Delta \mu_1, \Delta \mu_2, \ldots, \Delta \mu_{435} \right)$. A derivation is provided in \autoref*{sec:appendix-campaign-spending-model} in the Supplemental Appendix.

The first term in \autoref{eqn: Q_i probability of winning} is the effect of an increase in spending on the mean number of Republican seats while the second term is its effect on the variance. Parties have an incentive to influence the variance because they want to increase the probability of a desirable outcome. The trailing party will want to increase the variance to increase the probability of a major change in the election outcome while the leading party will want to do the opposite. The trailing party can increase the variance by spending more on districts in which its candidate it losing and the leading party can decrease the variance by spending more on districts in which it is winning. Intuitively, the leading party does not need to worry about districts in which it is losing because it only needs to make sure that it holds onto the one's it is leading in.

As shown by \citet{stromberg2008electoral}, an alternative interpretation of~\autoref{eqn: Q_i probability of winning} is that it is the probability that (i) a district is decisive in whether or not a party wins a majority of seats and (ii) the district is a swing district. Following Stromberg, I call such a district a ``decisive swing district''. The probability of being a swing district is the probability that an electoral race is tied (or at least very close), while a district is decisive if winning (or losing) that district would make the difference between winning (or losing) a majority of seats. The idea that parties should spend more money on swing districts is consistent with $Q_i^{seats}$ in~\autoref{eqn: Q_i expected seats}. The idea that parties should spend more on decisive districts differentiates the two maximization problems.

\subsection{Functional form} \label{sec:functional-form}
In order to solve for equilibrium spending, $e_i^{J*}$ and calculate $Q_i$, it is necessary to make an assumption about the functional form of $u(e_i^J)$. One functional form particularly amenable to empirical analysis is the logarithmic form, $u(e_i^J)= \theta \log (e_i^J)$, which results in the first order condition for district $k$ and party $J$,
\begin{align} \label{eqn: equilibrium spending}
e_k^{J*} = \frac{Q_k}{\sum Q_i}E^{J}.
\end{align} 
Each party spends the same fraction of the budget on district $k$, but $e_i^{R*}$ only equals $e_i^{D*}$ if both parties have identical budgets so that $E^{R} = E^{D}$.\footnote{For a formal proof see \citet{stromberg2008electoral}.} \autoref{eqn: equilibrium spending} implies that $Q_i$ is evaluated at $\Delta u_i = \theta \log(E^D/E^R)$, which reduces to $\Delta u_i=0$ when the budgets are equal. If $\theta$, $E^D$ or $E^R$ are unknown (and time-varying), then this term will be incorporated into the national shock, $\delta$, during estimation.

\section{Model Estimation} \label{sec:model-estimation}
To calculate $Q_i$, it is necessary to estimate the variances of the district and national shocks, $\sigma^2$ and $\sigma^2_\delta$, as well as the two-party vote, $V_i$. In this section I describe a Bayesian methodology that can estimate these parameters using historical political and economic information, and when available, polling data. The historical information provides a forecast of the election as of September 1st in each election year and polling data from September 1st through election day is used to update forecasts as campaigns progress. 

\subsection{A Bayesian Hierarchical Model}
Previous research shows that national elections are highly predictable from one year to the next using historical data \citep[e.g.,][]{campbell1992forecasting, gelman1993american, kastellec2008predicting}. Consistent with these historical models and~\autoref{eqn: Republican wins}, I model the Democratic share of the two party vote as a linear function of a matrix of explanatory variables, $X_{iy}$ (see \autoref*{sec:forecast-vars} in the Supplemental Appendix), national shocks, and district shocks,
\begin{align}
v_{iy}&= X_{iy}\beta + \delta_y + \epsilon_{iy}.
\end{align}
Since $\delta_y$ and $\epsilon_i$ are assumed to be normally distributed, this can be estimated using the Bayesian hierarchical model,
\begin{align}
v_{iy} &\sim N\left(X_{iy}\beta + \delta_y,  \sigma^2\right), \label{eqn: hierarchical linear model} \\
\delta_y &\sim N(0, \sigma^2_\delta), \label{eqn: hierarchical linear model time effects}
\end{align}
where $\beta$ is a vector of coefficients and $\delta_y$ is a random effect centered at 0. Uniform prior distributions were used for $\beta$, $\sigma$ and $\sigma_\delta$.

\subsection{Incorporating Polls with a Bayesian DLM}
Although national elections are highly predictable using historical data, forecasts that incorporate polls become increasingly accurate as election day nears \citep{linzer2013dynamic}. A common method for combining polls with historical regressions is to treat polls as additional data points. This technique is commonly used by researchers and media outlets forecasting presidential and Senate elections.\footnote{See, for instance, the Huffington Post's forecasts at \url{http://elections.huffingtonpost.com/}, which are based on Simon Jackman's poll-tracking model; Drew Linzer's forecasts at \url{http://votamatic.org/}; neuroscientist Sam Wang's website \url{http://election.princeton.edu/}; and Nate Silver's \url{http://fivethirtyeight.com/}.} The primary difficulty is that the polls are highly correlated and should not be treated as independent data. As a result, forecasters attempt to average the polls so that the most informative ones receive the most weight. This weighted average of polls can then, in turn, be combined with information from the regression analysis, with weights that should be based on their respective variances.

As noted by Nate Silver (\citeyear{silver2014ratings}), the variability of a poll's forecast can be thought of as a function of three major components: sampling error, temporal error and pollster-induced error. The first two terms are relatively straightforward: sampling error occurs because each poll is based on a sample from the electorate and temporal error is due to uncertainty about opinion shifts between the date a poll is taken and election day. The final term, pollster-induced error, can be thought of as the error left over after accounting for sampling and temporal error. A major part of this residual term can be attributed to house effects, or time-invariant biases specific to certain pollsters. However, this error can also occur due to other polling difficulties such as undecided voters, respondents who will not vote in the actual election or respondents that do not express their true voting intentions.

Here, I utilize a state-space framework that can sequentially adjust forecasts as new polls become available. This model-based poll averaging approach is very similar to the state-space poll-tracking model employed by Simon Jackman \citep{jackman2005pooling, jackman2009bayesian} and the forecasting model based on reverse-random walks used by Drew Linzer \citep{linzer2013dynamic}---which built on the idea used in \citet{strauss2007florida}. 

One important feature of House elections that must be accounted for is that district polling is sporadic both over time and across districts (see \autoref*{sec:poll-data} in the Supplemental Appendix). The incomplete nature of the data is important for calculating district and national errors because national errors based solely on district polling use less than half of all districts at any given date and the subset of districts available to calculate national errors changes over time (since different districts are polled at different times). One way around this is to use the generic congressional vote as a measure of the national vote, since, unlike district polls, polling firms begin conducting polls of the generic congressional vote for the next election at a consistent rate almost as soon as election results are in.

To incorporate the national polls, I separate the vote in each district into the national vote and the district vote relative to the national vote as in \citet{lock2010bayesian} and \citet{{strauss2007florida}}. This separation allows me to use all available polling data to decompose national and local variation as required by the theoretical model.\footnote{Another strategy is to model the correlation between the national and district polls in a multivariate time-series model (see \citet{jackman2012prediction} for a brief explanation). This approach is not taken here because it is not consistent with the theoretical model used in this paper.}

The model of the national vote follows the model employed in \citet{jackman2005pooling} and \citet{jackman2009bayesian}, which provides a framework for ``pooling'' the polls over the course of a campaign. To set notation, let $t=1,\ldots,T$ represent days of the campaign where $t=1$ corresponds to the first day of the campaign season and $t=T$ is election day. Furthermore, let $k$ index a poll with sample size $N_k$. Since the sample size of each poll is relatively large, the observed proportion of respondents who report that they intend to vote democratic, $y_k = n_k/N_k$ is approximated well by a normal distribution,
\begin{align}
y_k \approx N(\pi_k, \sigma^2_k),
\end{align}
where $\sigma^2_k= y_k(1-y_k)/N_k$. However, the parameter of underlying interest is not $\pi_k$, but the actual state of national opinion at time $t$. The $\pi_k$ are consequently modeled as a function of two components: the actual state of opinion, $\mu_t$, and a house effect, $\lambda_j$, specific to polling firm $j = 1,\ldots, J$,
\begin{align} \label{eqn pi}
\pi_k = \mu_{t[k]} + \lambda_{j[k]}.
\end{align}
\autoref{eqn pi} is not identified because one could shift $\mu_{t[k]}$ up/down and $\lambda_{j[k]}$ down/up by the same constant without changing the value of $\pi_k$. As a result, I use the identifying restriction that the house effects sum to zero, $\sum_j \lambda_j = 0$.

As currently specified, the model only provides a snapshot of national opinion on any given day. To forecast the election, it is necessary to estimate $\mu_T$, which is an estimate for national opinion on the day of the election. Since forecasts are made on days $t' <T$, it is therefore necessary to make assumptions about the movement of $\mu_t$ from one day of the campaign to the next. Since there is no reason to expect there to be any trends in polling, it is reasonable to expect $\mu_t$ to follow a random walk, so that the full model can be written as,
\begin{align}
\label{observation eqn national}
y_k &= \mu_{t} + \lambda_{j} + v_k, \; v_k\sim N(0, \sigma^2_k)\\ 
\label{system eqn national}
\mu_{t} &= \mu_{t-1} + w_\mu, \; w_\mu \sim N(0, \sigma^2_{\mu}),
\end{align}
where $\sigma^2_\mu$ is an estimate of the daily change in $\mu_t$.

A model for the district vote relative to the national vote proceeds in the same manner as the model for the national vote, but with a few differences. The first difference is that it is impractical to correct for house effects because there are only a few polls published per polling firm. The second difference is that national opinion at time $t$ is not actually observed, so the relative vote cannot be observed either. In practice, this is not a large problem because national opinion, $\mu_t$, is estimated very precisely using~\autoref{observation eqn national} and~\autoref{system eqn national} due to the abundance of large national polls.\footnote{The standard deviation of $\mu_t$ is typically around $0.004$.}

For the model of the relative district vote, let $l$ index district polls and continue to let $i$ index a district. Define the deviation of a district poll from the national vote as $d_l = y_l - \mu_{t[k]}$. The DLM for the relative district vote is then,
\begin{align}
\label{observation eqn district}
d_l &= \xi_{it} + v_l, \; v_l\sim N(0, \sigma^2_l)\\ 
\label{system eqn district}
\xi_{it} &= \xi_{i,t-1} + w_\xi, \; w_\xi \sim N(0, \sigma^2_{\xi}), 
\end{align}
where $\sigma^2_l = y_l(1-y_l)/N_l$, $N_l$ is the sample size of the $l$th poll, $\xi_{i[l]t[l]}$ is an estimate of the deviation of opinion in state $i$ from national opinion at time $t$, and $\sigma^2_{\xi}$ captures the variance of day to day movements in $\xi$. \autoref{observation eqn district} and~\autoref{system eqn district} are just a simple multivariate extension of the model of the national vote that ignore house effects.

To incorporate information from the historical regression, forecasts from the hierarchical model are treated as pseudo election day polls for both the national and district models. The two-party vote given to the national pseudo poll is the mean average district vote from the hierarchical model and the Democratic vote share given to each district's pseudo poll is the mean of the district forecast from the regression less the mean of average district vote. The corresponding variances are calculated using the posterior predictive distributions of these quantities.\footnote{See~\autoref{sec: Results from the DLM} for more details.} The regression forecasts in the national and district models consequently receive weights proportional to the regression forecast errors of the average district and relative district vote respectively. 

The overall forecast of the two-party vote for Democrats from each district is $\mu_T$ + $\xi_{iT}$. Separate forecasts of $\mu_T$ and $\xi_{iT}$ can essentially be estimated using a Kalman filter\footnote{The Kalman filter is commonly used in engineering to track the movement of objects such as satellites or aircraft that are measured with noisy data. It is also frequently used in Macroeconomics and in political science to track public opinion.}. Importantly, when estimating $\mu_T$ and $\xi_T$ prior to the election, there will be gaps between the last published poll and the pseudo poll from the regression; the Kalman filter helps bridge this gap by pushing $\mu_t$ and $\xi_{it}$ forward toward election day. The Kalman filter is also instructive because it quantifies the relative weight attached to previous versions of the states and new polls. In particular, polls receive more weight when the sampling error is lower, they are completed closer to election day, there is less movement in the polls, and the polling firm is less biased (see \autoref*{sec:dlm-posterior-distribution} in the Supplemental Appendix for explicit formulas).

The Kalman filter assumes that the variances of the states are known. Since, in practice, this is clearly not the case, I estimate all of the model parameters jointly using Bayesian methods. To do so, I assign the unknown variance parameters, $\sigma_\mu^2$ and $\sigma_\xi^2$, inverse gamma priors. The house effects, $\lambda_j$, are given a normal prior centered at $0$. The posterior density is simulated with a Gibbs sampler, which is described in~\autoref*{sec:dlm-gibbs} in the Supplemental Appendix.

\section{Forecasting the Two-Party Vote and Calculating $\mathbf{Q_i}$}\label{sec:forecasting-results}
\subsection{Forecasts using the Bayesian Hierarchical Model} \label{sec: results hierarchical model}
The hierarchical model was implemented using Stan \citep{dev2016rstan} and fit 5 separate times using post 1980 data to forecast (out-of-sample) the 2000, 2004, 2006, 2008 and 2010 elections.\footnote{For example, the 2000 election was fit using elections from 1980 to 1998; the 2004 election was fit using elections from 1980 to 2000 (recall that the model excludes years ending in 2); and so on.}. Uncontested seats were dropped from the model because parties would have known which districts were uncontested by September 1st.\footnote{Signature-filing deadlines in districts are all before September 1st.}\footnote{I also dropped the few races with third party candidates. These do not impact the calculations of $Q_i^{maj}$ because they all occurred before 2000. Independents Bernie Sanders of Vermont and Virgil Goode of Virginia are classified as a Democrat and a Republican respectively.} The posterior distribution for each of the 5 models was simulated using the last half of 5 chains of $2,000$ iterations each. The Gelman and Rubin potential scale reduction factor $\hat{R}$ was approximately $1$ for all model parameters in all 5 fits, which suggests that the Markov Chain successfully converged each time. 
 Details of the model fit are discussed in \autoref*{sec:forecast_hierarchical} in the Supplemental Appendix.

Forecast performance was evaluated in two primary ways. First, I calculated the root mean square forecast error (RMSFE), $\sqrt{E[(f_{iy} - v_{iy})^2]}$, where $f_{iy}$, is the mean of the posterior predictive distribution of the two party vote and $v_{iy}$ is the observed vote. The RMSFE was $\bhmrmse$ and the winner was only picked incorrectly $\bhmwrongwinner\%$ of the time. 

Second, I examined the plausibility of the forecast uncertainty. The forecast distribution is shown in \autoref{fig:Forecasts of the Number of the Percentage of Democratic Seats}, which is a histogram of the posterior predictive distributions of the fraction of seats won by Democrats in each of the five non-redistricting year elections from 2000 to 2010.\footnote{ The posterior predictive distribution for the number of seats is formed by simply counting the number of districts that had vote shares over $0.5$ for each of the $5,000$ draws from the posterior predictive distributions of $v_{i\tilde{y}}$ for each forecast year. Uncontested seats are not included in these estimates.} The actual fraction of Democratic seats is usually within the $95\%$ credible interval, but the intervals are not unreasonably wide either, which suggests that decomposing the error into district and national components is a reasonable approach. The 2010 election is an outlier since nearly all of the close elections broke toward the Republicans and large number of Democratic incumbents were defeated by Republican challengers. 

\begin{figure}[!htb]
\centering
\includegraphics{../figs/seats_hist.pdf}
\vspace{.5cm}
\caption{Forecasts of the Number of the Percentage of Democratic Seats}
\label{fig:Forecasts of the Number of the Percentage of Democratic Seats}
\begin{minipage}{\linewidth}
\footnotesize
\emph{Notes:} The histograms are from the posterior predictive distribution of the hierarchical model for each election year.
\end{minipage}
\end{figure}

\subsection{Forecasts using the DLM} \label{sec: Results from the DLM}
The posterior density of both the national and district DLM's were simulated using $6,000$ iterations of the Gibbs Sampler with a burn-in of $1,000$ iterations. To reduce the computational burden the campaign is divided into two week periods and the model is (retrospectively) estimated every two weeks during the month's of September and October. Polling data after a desired forecasting date are removed to ensure that only data that would have been available at the time is used. This yields four separate forecasts of the 2010 election in addition to the prior from the hierarchical model: a mid September (1.5 months prior to election day), late-September (1 month prior to election day), mid-October (2 weeks prior to election day) and late-October (just before the election) forecast. Trace plots of the parameters suggest that the Markov Chain converged each time and are available upon request.

Forecast summaries are presented in \autoref{fig:Forecasts of the 2010 National Vote by Date} and \autoref{fig:Forecasts of the Democratic Fraction of Seats in the 2010 Election}. \autoref{fig:Forecasts of the 2010 National Vote by Date} focuses on the forecast of the national vote. The dark dotted line is the DLM forecast (mean of the posterior distribution of $\mu_T$) and the error bars are $95\%$ credible intervals. The light dotted lines from top to bottom are the regression based forecast from the hierarchical model, the actual average district vote and an average of polls from the latest available two-week period.\footnote{The actual average district vote includes uncontested seats, which were given vote shares of 0.25 in Republican districts and 0.75 in Democratic districts.} Forecasts are reported for the standard model that include the regression estimate as a final pseudo poll (the ``prior'' model) and an alternative specification that does not (the ``no prior'' model). Standard errors are considerably smaller for the ``prior'' forecast than the ``no prior'' forecast although the difference shrinks as election day gets closer because there is less and less temporal error in the polls. Due to this temporal error, the forecast of the ``prior'' model does not deviate from the regression forecast until mid-October, but as temporal error decreases more weight is placed on the polls and the forecast is eventually nearly identical to the actual average district vote. On the other hand, the ``no prior'', or polls only model, hugs the polling average closely and predicts that the national vote will be considerably more Republican. The ``no prior'' model lies slightly above the polling average though because the model accounts for House effects and the most prolific pollsters (Rasmussen Reports and Gallup) leaned Republican during the campaign (see \autoref*{fig:house_effects} in the Supplemental Appendix). 

\begin{figure}[!htb]
\centering
\includegraphics{../figs/dlmnatpred.pdf}
\vspace{.5cm}
\caption{Forecasts of the 2010 National Vote by Date}
\label{fig:Forecasts of the 2010 National Vote by Date}
\begin{minipage}{\linewidth}
\footnotesize
\emph{Notes:} The plot labeled ``No prior" plots results from the DLM that does not include a final national pseudo poll based on the regression analysis; the plot labeled ``Prior" includes this final pseudo poll. Vertical bars are $95\%$ credible intervals for the forecast of the national vote from the DLM (points are median of the simulated vote). The upper dotted line is the point estimate of the regression based forecast (the mean of posterior distribution of the average district vote from the hierarchical model). The middle dotted line is the actual average district vote for Democrats. The lower dotted line is an average of all national polls during each time period (i.e. the poll average at the 2 month mark is all polls from days between 2 and 1.5 months before the election).
\end{minipage}
\end{figure}

\autoref{fig:Forecasts of the Democratic Fraction of Seats in the 2010 Election} displays forecasts of the fraction of seats won by the Democrats after excluding uncontested seats. The upper light dotted line labeled ``regression forecast'' is identical to the mean of the histogram for the 2010 election in~\autoref{fig:Forecasts of the Number of the Percentage of Democratic Seats} and the reported fraction of actual seats won excludes uncontested seats as well. The forecast (and 95\% credible intervals) are calculated by taking the fraction of seats with a predicted vote share greater than $0.5$ for each simulated draw of $\mu_T + \xi_{iT}$. Like the forecast of the national vote, the ``prior'' model does not begin to move away from the regression forecast until mid-October and the ``no prior'' forecast changes considerably more from period to period. The ``no prior'' model provides a forecast of the Democratic seat share that is very close to the actual Democratic seat share while the ``prior'' model overestimates the electoral success of the Democrats. 

\begin{figure}[!htb]
\centering
\includegraphics{../figs/dlmseats.pdf}
\vspace{.5cm}
\caption{Forecasts of the Democratic Fraction of Seats in the 2010 Election}
\label{fig:Forecasts of the Democratic Fraction of Seats in the 2010 Election}
\begin{minipage}{\linewidth}
\footnotesize
\emph{Notes:} The plot labeled ``No prior" plots results from the DLM that does not include a final pseudo polls based on the regression analysis; the plot labeled ``Prior" includes these final pseudo polls. Vertical bars are $95\%$ credible intervals for the forecast of the Democratic fraction of seats from the DLM (points are median of the simulated vote). The upper dotted line labeled ``Regression forecast'' is the mean of the posterior distribution of the Democratic seat share from the hierarchical model. The lower dotted line is the fraction of seats won by Democrats. All calculations omit uncontested seats.
\end{minipage}
\end{figure}

It is tempting to use this evidence to discount the regression based prior but it is worth remembering that 2010 is an outlier election, nearly all of the close elections broke toward the Republicans, and comparing predicted seats to the observed seats is only one of many possible ways to evaluate forecasts. For a more comprehensive  examination of the Bayesian estimation of the DLM and its forecast performance see~\autoref*{sec:forecast_dlm} in the Supplemental Appendix. 

\subsection{Calculating $Q_i$} \label{sec: calculating Q}
Armed with parameter estimates from the hierarchical model and the DLM, one can use the estimates of $V_{i}$, $\sigma$ and $\sigma_\delta$ to calculate the $Q_i$'s from equations~\ref{eqn: Q_i expected seats} and \ref{eqn: Q_i probability of winning}. In the theoretical model, these parameters are assumed to be known with certainty. But, when using a Bayesian approach this is not the case since the parameters have their own probability distributions. 

Accounting for this additional uncertainty with the hierarchical model is straightforward: I calculate $Q_i$ by averaging over all of the unknown parameters. In other words, I add extra uncertainty to the maximization problem by integrating the objective functions over $p(\beta, \delta_t, \sigma, \sigma_\delta)$ instead of just integrating over $h(\delta_t)$.

$Q_i$ is calculated in a similar manner when the model is estimated using the DLM. Because I separate the national vote and the district vote relative to the national vote, there is a probability distribution for each component. Due to the normality assumptions, both the forecasts of the national vote, $\mu_T$, and the district vote, $\xi_{iT}$, are normally distributed. $\sigma$ can consequently be estimated with the standard deviation of the posterior distribution of $\xi_T$. A posterior distribution for $V_i + \delta$ is simulated by summing the mean of the posterior distribution of $\xi_T$ and each simulated draw from the posterior distribution of $\mu_T$. In total, this provides a range of forecasts depending on the national error as well as an estimate of the district level error as required by the theory.

As discussed in~\autoref{sec:equilibrium}, party goals can have an important impact on $Q_i$. The implication of these goals are illustrated in~\autoref{fig: $Q_i$ versus the mean forecast of the Democratic vote in the 2008 election}, which shows how $Q_i$ depends on forecasted Democratic vote shares. When parties want to maximize the expected number of seats, they should spend the most resources on the closest elections. This is clear in the leftmost plot in which $Q_i$ follows a bell shaped pattern peaking when the forecasted vote share is $0.5$. 

The strategies are more intricate when the parties maximize the probability of winning a majority of seats. In this case, the parties should spend the most resources on decisive swing districts, or districts that are most likely to be close when winning that district will cause one party to win one more seat than the other party. This, in turn, implies that the trailing party should spend more resources in districts that they are losing in an effort to make the election more unpredictable. These incentives are best illustrated in the 2008 election when the Democratic party was expected to win a large majority of seats.\footnote{Forecasts from the hierarchical model predict that the Republicans would have won, on average, $\predseats2008$ of the necessary 218 seats for a majority; in reality, they won 178 seats.} As shown in the plot, the Republican's optimal strategy (assuming they were only concerned with winning a majority of seats), was to spend the most resources in districts with a predicted Democratic vote share over $0.5$. Since the number of seats won by both parties would have only have been close if the national swing shifted drastically in the Republican's favor, $Q_i$ is maximized for districts with a vote share close to $0.6$. Interestingly, the cost of spending on districts that Republicans were expected to barely win has such an adverse effect on the variance of the election that $Q_i$ is actually negative in these districts.
 
\begin{figure}[!htb]
\includegraphics{../figs/qplot.pdf}
\vspace{.5cm}
\caption{$Q_i$ versus the mean forecast of the Democratic vote in the 2008 election}
\label{fig: $Q_i$ versus the mean forecast of the Democratic vote in the 2008 election}
\begin{minipage}{\linewidth}
\footnotesize
\emph{Notes:} The forecasted Democratic vote share in each district is the mean of the posterior predictive distribution from the hierarchical model.
\end{minipage}
\end{figure}

\section{Relationship Between $\mathbf{Q_i}$ and District Spending} \label{sec:actual-vs-optimal}
The relationship between $Q_i$ and spending depends on the functional form of $u(e^J_i)$. I use the logarithmic utility function analyzed in~\autoref{sec:functional-form}, which yields an equilibrium in which $=e_i^{J*}/\sum e_i^{J*} =Q_i/\sum Q_i$. That is, I estimate the regression equation,
\begin{align} \label{eqn: regression eqn}
\frac{e_{iy}^{J}}{\sum e_{iy}^{J}} &= \gamma \frac{Q_{iy}}{\sum Q_{iy}} + X_{iy}\beta + \eta,
\end{align} 
where $e_{iy}^{J}$ is observed spending in district $i$ and year $y$ and $X_{iy}$ contains other covariates that affect district spending.
 
\subsection{Correlations}
\autoref{fig:Correlation Between Q and Spending, by Contributor Type} plots the correlation between $Q_i$ and spending by contributor type and the goal of the parties (see \autoref*{sec:campaign-spending} in the Supplemental Appendix for details on classifying contributor types and the campaign spending data more generally). The top and bottom panels show the correlation with spending between $Q_i^{maj}$ and $Q_i^{seats}$, respectively. The plot highlights two primary aspects of the data. First, there are few differences in spending patterns between contributor types. Surprisingly, the correlations for party affiliated groups (national party committees, party-connected committees, allied PACs) are not significantly higher than the correlations for other groups. 

Second, the correlations are not very sensitive to party goals except in 2008. In~\autoref{sec: calculating Q} I showed that assumptions about party goals impacted the values of $Q_i$ greatly in 2008 because the Democrats were expected to win the House by almost 80 seats. The 2008 election can therefore be used to identify party goals. The huge decline in the correlation between spending and $Q_i^{maj}$ but not between spending and $Q_i^{seats}$ suggests that parties maximize the expected number of seats rather than the probability of winning a majority of seats. 

\begin{figure}[!htb]
\includegraphics{../figs/corbytype.pdf}
\vspace{.5cm}
\caption{Correlation Between $\mathbf{Q_i}$ and Spending, by Contributor Type}
\label{fig:Correlation Between Q and Spending, by Contributor Type}
\begin{minipage}{\linewidth}
\footnotesize
\emph{Notes:} Spending is the sum of spending for Republicans and Democrats in a district by a given contributor type. The top panel shows the correlation between $Q_i^{maj}$ and spending while the bottom panel shows the correlation between $Q_i^{seats}$ and spending.
\end{minipage}
\end{figure}

According to Stromberg's model, if the effect of spending on vote share is of the log form, then both parties should spend the same proportion of their funds in each district. An examination of spending patterns across districts by party is consistent with this notion. For instance, the simple correlation between spending on Democratic candidates and spending on Republican candidates is $\corpartyexp$. Moreover, there are only small differences in the correlation between $Q_i$'s and spending by party (\autoref*{fig:cor-q-party} in the Supplemental Appendix), although $Q_i^{seats}$ is slightly more correlated with spending on Republicans than spending on Democrats.

The correlations presented thus far use the hierarchical model to calculate $Q_i$. One would expect that the DLM could improve the fit between the model and the observed data. \autoref{fig:Correlation Between Q and PAC Spending by Date and Model, 2010 House Election} examines this by comparing the correlation between $Q_i^{seats}$ calculated using three different models (the hierarchical model, the prior informed DLM and the non-prior informed DLM) and spending at different dates during the 2010 campaign.\footnote{The figure omits correlations made just prior to the election (late October) because the correlations are significantly lower and distort the figure: the correlations using the prior-informed DLM, no-prior DLM and hierarchical model are $\cordlmfinal$, $\cordlmnpfinal$ and $\corbhmfinal$ respectively. This likely occurs because there are only a couple of days between the final forecast date and election day.} Spending is the sum of all spending in a district between election day and the forecast date.

In early September, or two months prior to the election, forecasts are only available from the hierarchical model so I assign all three models forecast values equal to the forecast from the hierarchical model. The figure shows that the values of $Q_i^{seats}$ calculated using the DLM's match observed spending better than the values of $Q_i^{seats}$ calculated using the hierarchical model, although the $Q_i^{seats}$ from the hierarchical model is still accurate. The correlations between the values of $Q_i^{seats}$ estimated using the hierarchical model and spending decrease in a linear fashion over time while the correlations based on the DLM forecasts reach a peak of around 0.8 one month before the election.  There is little difference between the performance of the ``prior'' and ``no prior'' DLM's, although the correlations between the ``no prior'' DLM and spending are somewhat more variable. 

Overall, these findings suggest that campaign donors use polls to evaluate the competitiveness of a district and update these beliefs when new polls become available. In addition, \autoref*{sec:qi_spending} in the Supplemental Appendix shows that donors contribute in a manner more consistent with $Q_i^{seats}$ than other measures of district competitiveness. 

\begin{figure}[!htb]
\includegraphics{../figs/cormodels.pdf}
\vspace{.5cm}
\caption{Correlation Between $\mathbf{Q_i}$ and PAC Spending by Date and Model, 2010 House Election}
\label{fig:Correlation Between Q and PAC Spending by Date and Model, 2010 House Election}
\begin{minipage}{\linewidth}
\footnotesize
\emph{Notes:} Spending refers to all spending by PACs, party committees and individuals contributing over \$200 between a given date and election day.
\end{minipage}
\end{figure}

\subsection{Alternative Predictors of District Spending}
\autoref{table: OLS Regressions on Candidate Spending Shares} reports regression estimates of $\gamma$ and $\beta$ (from~\autoref{eqn: regression eqn}) when analyzing spending on Democratic candidates (panel A) and Republican candidates (panel B). The ``Q share'', $Q_{iy}^{seats}/ \sum_i Q_{iy}^{seats}$, is estimated using the hierarchical model. Mean and median spending shares across districts are $0.23\%$ and $0.085\%$ respectively. 

The first column reports an estimate of a simple linear regression (with an intercept) with the Q share as the only explanatory variable. The Q share coefficients in both panels A and B are strongly positively associated with actual spending and significantly different than $0$. The coefficients are somewhat inconsistent with the equilibrium spending conditions in~\autoref{eqn: equilibrium spending} though because they are significantly different than $1$; that said, the coefficients are fairly close to $1$ and the $R^2$ values are high.

\begin{table}[!ht]
\footnotesize
\begin{center}
\begin{threeparttable}
\caption{OLS Regressions on Candidate Spending Shares (\%)} \label{table: OLS Regressions on Candidate Spending Shares}
\begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}d{-1}d{-1}d{-1}d{-1}d{-1}}
\vspace{-5pt}\\
\hline
\hline
\multicolumn{1}{c}{} & \multicolumn{1}{c}{(1)} & \multicolumn{1}{c}{(2)}& \multicolumn{1}{c}{(3)} & \multicolumn{1}{c}{(4)}& \multicolumn{1}{c}{(5)} \\
\hline
\multicolumn{1}{l}{\emph{Panel A. Democrats}} & \multicolumn{5}{c}{}\\
\ExpandableInput{../tables/regexp_dem.txt}
\multicolumn{1}{l}{District fixed effects?}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{Yes} \\
\hline
\multicolumn{1}{l}{\emph{Panel B. Republicans}} & \multicolumn{5}{c}{}\\
\ExpandableInput{../tables/regexp_rep.txt}
\multicolumn{1}{l}{District fixed effects?}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{Yes} \\
\hline
\hline
\end{tabular*}
\scriptsize
Notes: The dependent variable is the share of yearly spending by all PACs in each district. The unit of analysis is a candidate-district-year. Robust standard errors are in parentheses. \emph{Open seat}, \emph{Incumbent}, \emph{Ways and Means Committee}, \emph{Ways and Means Committee}, and \emph{Party Leadership} are indicator variables equal to 1 if candidates are running in open seats, incumbents, members of the Ways and Means Committee, chairs of a major committee or House party leaders. Party leaders include the speaker of the House, the majority/minority leaders and the majority/minority whip. \emph{Probability of victory} is the probability that a candidate wins the election calculated using the posterior predictive distribution from the hierarchical model.
\end{threeparttable}
\end{center}
\end{table}

The second column adds two dummy variables indicating that a candidate is an incumbent or running in an open seat (the omitted category is a challenger in an incumbent district). Each variable is statistically significant and positively associated with spending in both panels. The $R^2$ in column 2 improves considerably in the Democratic specification and marginally in the Republican one.

Columns 3 and 4 add influence-motivated variables that campaign donors might consider when deciding which campaigns to contribute to. The influence variables in column 3 are three indicator variables for whether candidates are member of the Ways and Means Committee, party leaders, or committee chairmen. In column 4, I include an estimate of the probability that a candidate will win the election (0 to 1 scale) since campaign donors concerned with establishing a relationship with a candidate should prefer to donate to a candidate who will be in office \citep[see for instance][]{snyder1990campaign}. The influence related variables have a small impact on the $R^2$ and are often not statistically different than zero. Being a party leader is the most important influence variable and is positive and statistically significant in both panel A and panel B.

To help alleviate concerns that the regression estimates might be biased, column 6 adds district fixed effect that control for time invariant district specific characteristics. The number of observations is smaller in this specification because the 2000 election is dropped since district lines changed in 2002. Adding the fixed effects improves the model fit and only has a small impact on the coefficients. Importantly, the Q share remains a highly significant predictor of actual spending.

As a whole, the regression estimates show that the Q share explains a large portion of the variation in actual spending shares. Other variables such as whether the candidate is an incumbent or the seat is open add additional explanatory power (especially for Democrats) but little is gained in terms of fit from adding influence related variables.

While spending in a district may be largely explained by the Q share, this ignores variation across donors. Organizations whose welfare depends heavily on policy decisions should have the largest incentives to influence policy. \autoref{table:Spending by the Financial Industry, Incumbent Races 2000 - 2010} looks at whether this is the case by analyzing the spending decisions of the financial industry, a group whose campaign goals might differ markedly from other organizations. Campaign contributions from the financial industry are defined as those coming from PACs classified as a member of the Finance, Insurance, and Real Estate industry by the CRP or from individuals employed in the same industry. The regression analysis examines the impact that being a member of the House Committee on Financial Services Committee has on contributions from these firms. The unit of analysis for the regressions is an incumbent candidate since challengers cannot serve on a congressional committee. The dependent variable is the district share of yearly spending by the financial industry on incumbents. 

\begin{table}[!ht]
\footnotesize
\begin{center}
\begin{threeparttable}
\caption{Spending by the Financial Industry, Incumbent Races 2000 - 2010} \label{table:Spending by the Financial Industry, Incumbent Races 2000 - 2010}
\begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}d{-1}d{-1}d{-1}}
\vspace{-5pt}\\
\hline
\hline
\multicolumn{1}{c}{Variable} & \multicolumn{1}{c}{(1)} & \multicolumn{1}{c}{(2)}& \multicolumn{1}{c}{(3)} \\
\hline
\ExpandableInput{../tables/regexp_fin.txt}
\multicolumn{1}{l}{District fixed effects?}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{No}& \multicolumn{1}{c}{Yes} \\
\hline
\hline
\end{tabular*}
\scriptsize
Notes: The dependent variable is the district share of yearly spending by the Finance, Insurance, and Real Estate industry on incumbents. Industry spending covers contributions from PACs and individuals (sorted by employer) donating at least \$200. The unit of analysis a district-year. Open seat districts are excluded from the analysis. Robust standard errors are in parentheses. 
\end{threeparttable}
\end{center}
\end{table}

Column 1 shows that the Q share is positive and statistically significant. Column 2 includes an indicator variables equal to 1 if an incumbent is a member of the Financial Services Committee and 0 otherwise. Since the chair and ranking minority members of the Financial Services Committee are likely to hold the most influence, I also include a dummy variable indicating such status. Both variables are statistically significant and have large positive coefficients. In column 3, which controls for district fixed effects, equilibrium spending and committee status remain statistically different than zero but being a chair or ranking minority member does not. This should not be seen as evidence that a leadership position on the committee is unimportant, but is instead likely a consequence of a fixed effect regression without enough variation in an explanatory variable. In summary, the financial industry appears to pursue both election motivated and influence motivated spending strategies.

\section{Discussion} \label{sec:discussion}
The results in this paper rely on two key modeling assumptions: First, it is assumed that political parties do not consider future elections, and second, campaign spending is assumed to increase vote share. In addition, the estimates of $Q_i$ tested in the empirical exercises are generated under the assumption that the relationship between campaign spending and vote share is logarithmic.

The first assumption has important implications regarding the objectives of political parties. For instance, one cannot rule out the possibility that parties maximize total seats in lopsided elections in order to increase the probability of majority control in the future. This may be especially relevant given that incumbents tend to receive more votes than challengers \citep{ansolabehere2002incumbency,gelman1990estimating, gelman2008estimating, lee2001electoral}.  In a dynamic context, parties may therefore pursue strategies that lie somewhere between the seat maximization and majority control equilibria derived in this paper. A key consideration is the extent to which parties trade off current elections for future ones and ways in which this trade off varies by electoral context. For example, how confidence must a party be that they will lose in order to determine that they would be better off using their resources to maximize the probability of winning a future election?

The second assumption is also important for a couple of reasons. For one, it influences the estimates of $Q_i$. Additionally, if the relationship between spending and vote share varies across different types of campaign resources, then parties might want to allocate different types of resources differently. For example, \citet{bartels1985resource} provides evidence that campaigns allocate instrumental resources (i.e., advertising funds and candidate appearances) differently than ornamental resources (i.e., state-level organizational funds and personnel).  

There is a large literature examining the extent to which campaign spending influences election results. Early research focused on the U.S. showed that campaign spending by challengers was very influential while spending by incumbents was not \citep{jacobson1978effects, jacobson1980money,jacobson1985money}. Later studies that have better accounted for endogeneity biases find that campaign spending by incumbents does impact the vote and that spending effects can be of roughly equal magnitude for challengers and incumbents \citep{erikson2000equilibria, gerber1998estimating, green1988salvation}. These more recent results are also consistent with a larger comparative literature both within and outside the U.S. showing that campaigning has electoral payoffs with respect to both voter turnout and the vote share \citep[e.g.,][]{denver2003constituency, gerber2000effects, hillygus2005campaign, pattie1995winning,marsh2004none, whiteley2003win}. 

A growing body of literature has also demonstrated that campaign effectiveness varies by electoral context. There is evidence that the effect of campaigning depends on political interest \citep{arceneaux2009mobilized, hillygus2005campaign, imai2011estimation, niven2001limits}, the type of electoral system \citep{karp2007getting}, electoral competitiveness \citep{fieldhouse2009effectiveness, gerber2004does}, and party management \citep{fisher2006relative, fisher2011electoral}.\footnote{Studies demonstrating that the marginal effect of campaign spending on the vote share is largest in close elections might help explain findings from prior studies in the U.S. that there were essentially no returns to spending by incumbents. In particular, if the effect of campaign spending is averaged over all incumbent elections, then estimates would be based primarily on elections where the marginal effect of a vote is the smallest (most elections in the U.S. House with incumbent candidates are not close).} Likewise scholars have found that campaign technique can have a large effect on campaign effectiveness. A robust finding is that traditional forms of campaigning such as face-to-face canvassing are more effective than more modern techniques like television canvasing or e-campaigning  \citep{aldrich2016getting, arceneaux2009mobilized, fisher2009evaluating, fisher2016all, gerber2000effects, imai2013estimating, pattie2003hanging}, although more modern techniques may become more effective as voters become more accustomed to them \citep{fisher2009evaluating, imai2005get, fisher2016all}. Studies have tended to show that in established democracies political advertising has no impact on turnout \citep{ashworth2007does, krasno2008televised} and its effect on voting preferences is short-lived \citep{ gerber2011large}, but more recently \citet{spenkuch2018political} used a regression discontinuity approach to show that political advertising increases vote share by modifying the partisan composition of the electorate.
  
It is also worth mentioning the finding that the correlation between predicted spending under the model and actual spending is nearly identical for party affiliated groups, individuals, and PACs. There are at least three potential explanations for this. First, it could suggest that the national parties are able to coordinate campaign efforts with individuals and groups that have similar political goals. This explanation is consistent with Herrnson's (\citeyear{herrnson2009roles}) view of political parties as multilayered coalitions. A second explanation that cannot be ruled out is that candidates have larger incentives to raise funds in tight races. This interpretation is consistent with the game theoretic model in \citet{erikson2000equilibria}. Intuitively, this occurs because an additional dollar of spending has a larger impact on the probability that a candidate will win an election when the projected vote share is closest to 1/2. There is some empirical support for this as well. For example, \citet{stein1994congressional} show that the most vulnerable candidates for reelection (as measured by their vote share in the previous election) are the most likely to obtain new grant money for their constituents. Similarly, \citet{bickers1996electoral} find that vulnerable incumbents use the grant system to deter quality challengers from opposing them. Third, all contributors might take cues from the same information (e.g., the election and polling data used for forecasting in this paper) and therefore make similar strategic decisions about which districts to contribute to.

The discussion in this section suggests a number of potential avenues for future research. First, the methods developed in this paper should be combined with information on the cost-effectiveness of different types of campaign spending. This could help researchers estimate how a campaign should allocate funds (e.g., television and radio advertising, face-to-face campaigning, etc.), which voters to target, and the extent to which actual resource allocations are consistent with these strategies. Second, studies should examine the extent to which actual resource allocation varies across electoral contexts given that the campaign effectiveness is expected to vary. Third, the assumption that the relationship between campaign spending and vote share is logarithmic should be tested and the implications of different functional forms should be explored. Fourth, clever empirical strategies are needed to help disentangle whether spending is concentrated in close elections because contributors want to influence elections or because candidates have larger incentives to raise funds. Finally, dynamic mathematical models are needed to derive optimal resource allocation strategies when parties maximize electoral outcomes over multiple elections.  

\section{Conclusion} \label{sec:conclusion}
This paper integrates Bayesian forecasts with Stromberg's \citeyear{stromberg2008electoral} probabilistic voting model to quantify the amount that political parties should spend on districts in U.S. House elections. The calculations are made using two assumptions about goals: first, parties maximize the expected number of seats and second, parties maximize the probability of winning a majority of seats. The empirical results support the first assumption but not the second one. The correlation between district spending and the amount that should have been spent if parties were maximizing the expected number of seats ranges from 0.5 to 0.8 during elections between 2000 and 2010. Correlations were highest when incorporating polling data and spending patterns tracked poll based forecasts during the 2010 election. Conversely, during the 2008 election in which optimal strategies differed greatly because the Democrats were predicted to win a large majority, observed spending is highly correlated with a spending strategy based on maximizing the expected number of seats but not with a spending strategy based on maximizing the probability of winning a majority of seats. The results also suggest that most political giving is done to affect elections rather than for other reasons like protecting incumbents or influencing candidates; only contributors with the most to gain from influencing policy (e.g., the financial industry) place as much weight on buying access to politicians as on influencing elections.

\pdfbookmark[1]{References}{References}
\bibliography{bibliography}

\end{document} 
